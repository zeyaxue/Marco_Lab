---
title: "MC_paper2_phyloseq_import"
author: "Zeya Zhengyao Xue"
date: "January 14, 2019"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.path = "figs/")
```

This file follows the analysis in QIIME2, which imports mapping file, feature table,
taxonomy and tree as a 4-component phyloseq object. 

## Setting up packages and working directory 
```{r}
library(phyloseq);packageVersion("phyloseq")
library(vegan);packageVersion("vegan")
library(ggplot2);packageVersion("ggplot2")
library(ggpubr); packageVersion("ggpubr") #  ggplot2 based publication ready fig
library(reshape2);packageVersion("reshape2")
library(cowplot);packageVersion("cowplot")
library(plyr)
library(dplyr)

path <- "~/Google Drive File Stream/My Drive/UC_Davis/Marco_lab/milk_microbiota/Mock_community/MC_paper2_QIIME2/"
```


## Import QIIME2 output and make phyloseq object
2/5/19: add Phase 3 results and import as the same ps object
```{r}
# Transpose the QIIME2 output in excel
# For the theoretical values, I can adjust its absolute reads to suit data set by
# changing values in the feature table
SeqTab <- read.table(file.path(path, "feature_table/5file-combined_table-dada2-mc2.txt"), header = TRUE, stringsAsFactors = FALSE)
colnames(SeqTab) <- gsub("X","",colnames(SeqTab))
row.names(SeqTab) <- SeqTab$OTUID
SeqTab <- SeqTab[,-1]
SeqTab <- as.matrix.data.frame(SeqTab)

# Read in metadata file
samdf <- read.csv(file.path(path,"mapping/5file-MC_paper2_samdf.csv"))
rownames(samdf) <- samdf$SampleID

# Read in exported rooted tree 
tree <- read_tree(file.path(path,"5file-tree.nwk"))

# Parse out taxonomic assignment in excel and remove confidence column
# keep only taxa included in the "feature-table-mc2.csv" file
# Species column removed
TaxTab <- read.table(file.path(path,"5file-taxonomy-mc2.tsv"), header = TRUE, sep = '\t', na.strings = NA)
rownames(TaxTab) <- TaxTab$FeatureID
TaxTab <- TaxTab[,-1]
TaxTab <- as.matrix.data.frame(TaxTab)

# merge as the phyloseq ready to use
ps <- phyloseq(otu_table(SeqTab, taxa_are_rows = TRUE), tax_table(TaxTab),sample_data(samdf), phy_tree(tree))
ps # 1052 taxa and 212 samples 

# Filter out singleton
ps <- filter_taxa(ps, function (x) {sum(x > 0) > 1}, prune=TRUE)
ps # 1049 taxa and 212 samples
write.csv(ps@otu_table, file.path(path,"feature_table/5file-feature-table-mc2.csv"))
```


## Filter ASVs based on taxonomy and abundance 
```{r}
# Show available ranks in the dataset
rank_names(ps)
# Create table, number of features for each phylum
table(tax_table(ps)[, "Phylum"], exclude = NULL)
# remove asv that was not assigned at phylum level
ps.Phy <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c(""))
ps.Phy # 1013 taxa and 212 samples
# Explore abundance to decide filter threshold
## Compute prevalence of each feature, store as data.frame
prevdf <- apply(X = otu_table(ps.Phy),
                MARGIN = ifelse(taxa_are_rows(ps.Phy), yes = 1, no = 2),
                FUN = function(x)(sum(x>0)))
# Add taxonomy and total read counts to this data.frame
prevdf <- data.frame(Prevalence = prevdf,
                     TotalAbundance = taxa_sums(ps.Phy),
                     tax_table(ps.Phy))
# plot the abudance per phylum 
ggplot(prevdf, aes(TotalAbundance, Prevalence / nsamples(ps.Phy),color=Phylum)) +
  # Include a guess for parameter
  geom_hline(yintercept = 0.01,  linetype = 2) + geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
# Most bacteria are in the Actinobacteria, Bacteroidetes, Firmircutes and Proteobacteria
# But I don't actually have Bacteroidetes members...

# Remove very low abudance ASVs independent of sample prevalence
x = taxa_sums(ps.Phy)
keepTaxa = which((x / sum(x)) > 0.00005)
ps.Phy05 <- prune_taxa(names(keepTaxa), ps.Phy)
ps.Phy05 # 197 taxa and 212 samples
```

## Determine rarefaction level for Alpha and Beta analysis later on
```{r}
set.seed(123)
# Read in function to calculate alpha diversity and rarefaction levels
calculate_rarefaction_curves <-dget(file.path("~/src/Marco_Lab/FUN_calculate_rarefaction.R"))

rarefaction_curve_data <- calculate_rarefaction_curves(ps.Phy05, c("Observed", "Shannon","Simpson"), 
                                                       rep(c(1, 2500, 5000, 7500, 10000), each = 10))
rarefaction_curve_data$SampleID <- gsub("X","",rarefaction_curve_data$SampleID)
# summarize alpha diversity
rarefaction_curve_data_summary <- ddply(rarefaction_curve_data, c('Depth', 'SampleID', 'measures'), 
                                        summarise, 
                                        Alpha_diversity_mean = mean(Alpha_diversity), 
                                        Alpha_diversity_sd = sd(Alpha_diversity))
# Add sample data
rarefaction_curve_data_summary_verbose <- merge(rarefaction_curve_data_summary, 
                                                data.frame(sample_data(ps.Phy)), 
                                                by.x = 'SampleID', by.y = 'row.names')
rarefaction_curve_data_summary_verbose <- rarefaction_curve_data_summary_verbose[, -1]

# plot out rarefaction curve
ggplot(rarefaction_curve_data_summary_verbose, aes(x = Depth, y = Alpha_diversity_mean, 
                                                   ymin = Alpha_diversity_mean - Alpha_diversity_sd, 
                                                   ymax = Alpha_diversity_mean + Alpha_diversity_sd,
                                                   color = SampleID, group = SampleID)) +
  scale_fill_brewer(palette = "Set2") + 
  geom_line()+
  geom_pointrange(size=0.1)+
  theme(legend.position="none") + #  remove legend
  facet_wrap(facets = ~ measures, scales = "free")
# export the library size to a csv file
write.csv(sample_sums(ps.Phy05), file.path(path, "mapping/library_size_ps.Phy05_5file.csv"))

# The diversity leveled out after 2500 seqs per sample, rarefy at 3990
# to keep the sample with the fewest reads that is no a NC (MC.50.2)
```

## Divide the ps object for different dataset 
### For taxonomy analysis based on "ps.REC.glom"
```{r include=FALSE}
# Clean up the taxonomy level
#make the deepest taxonomic identification in TaxTab as the recommened taxonomy (REC)
RECps <- dget("~/src/Marco_Lab/FUN_RECps.R") # Read in RECps function
ps.Phy.REC <- RECps(ps.Phy05@tax_table, ps.Phy05)
ps.Phy.REC # 197 taxa and 212 samples
ps.REC.glom <- tax_glom(ps.Phy.REC, taxrank = "REC", NArm = FALSE)
ps.REC.glom #  100 taxa and 212 samples

# Define function to get the average and raw value of the feature table 
AveFeatTab <- function(ps){
  df <- psmelt(ps)
  df.cast <- dcast(df, REC ~ For_AVE, mean, value.var = "Abundance")
  df.cast[, -1] <- lapply( df.cast[ , -1], function(x) x/sum(x, na.rm=TRUE) )
  df.cast
}
FeatTab <- function(ps){
  df <- psmelt(ps)
  df.cast <- dcast(df, For_AVE + SampleID ~ REC, value.var = "Abundance")
  df.cast
}


# 1. DNA extraction lysis method using the Total kit; BCMC1
samdf1 <- read.csv(file.path(path, "mapping/MC_paper2_samdf_BCMC1_total_lyse.csv"))
row.names(samdf1) <- samdf1$SampleID

# 2. DNA extraction kit with MoBio
samdf2 <- read.csv(file.path(path, "mapping/MC_paper2_samdf_BCMC1_MoBio.csv"))
row.names(samdf2) <- samdf2$SampleID

# 3. DNA extraction kit choice on 10 ml UHT milk; BCMC2
samdf3 <- read.csv(file.path(path, "mapping/MC_paper2_samdf_BCMC2_kit_10ml.csv"))
row.names(samdf3) <- samdf3$SampleID

# 4. PMA treatment
samdf4 <- read.csv(file.path(path, "mapping/MC_paper2_samdf_PMA.csv"))
row.names(samdf4) <- samdf4$SampleID

# 5. Sample storage
samdf5 <- read.csv(file.path(path, "mapping/MC_paper2_samdf_sample_storage.csv"))
row.names(samdf5) <- samdf5$SampleID

# 6. Sample Volume
samdf6 <- read.csv(file.path(path, "mapping/MC_paper2_samdf_total_vol.csv"))
row.names(samdf6) <- samdf6$SampleID

# 7. phase 3 kit, cleanup and lysing method 
samdf7 <- read.csv(file.path(path, "mapping/phase3_samdf.csv"))
row.names(samdf7) <- samdf7$SampleID

# 8. UHT milk negative control
samdf8 <- read.csv(file.path(path, "mapping/MC_paper2_mapping_UHT.csv"))
row.names(samdf8) <- samdf8$SampleID

# create ps list with all phyloseq objects and transform to relative proportions
## create samdf list with all samdf data frames
samdfList <- list(samdf1, samdf2, samdf3, samdf4, samdf5, samdf6, samdf7, samdf8)
names(samdfList) <- c(1:8)
## Update the sample data of the phyloseq objects (to include For_AVE column)
psList <- list()
for (i in 1:8){
  psList[[i]] <- phyloseq(sample_data(samdfList[[i]]), otu_table(ps.REC.glom),
                          tax_table(ps.REC.glom), phy_tree(ps.REC.glom))
  print(psList[[i]] )
}

# use the function to write feature table lists and write out csv
AveFeatTab.list <- lapply(psList, AveFeatTab)
names(AveFeatTab.list) <- c(1:8)
mapply(write.csv, AveFeatTab.list, 
       file = paste0(path, "feature_table/AveFeatTab_", names(AveFeatTab.list), ".csv"))

FeatTab.list <- lapply(psList, FeatTab)
names(FeatTab.list) <- c(1:8)
mapply(write.csv, FeatTab.list, file = paste0(path, "feature_table/FeatTab_", names(FeatTab.list), ".csv"))
```

#### Taxonomy plot for individual values
```{r}
TaxBar <- function(ps, var1, var2, lvl = NULL, lvl2 = NULL, w, h, path.out){
  ExpTaxa <- c("Bacillaceae","Bacillus","Corynebacterium","Clostridiaceae",
               "Clostridium","Enterococcus","Escherichia","Lactococcus",
               "Pseudomonas","Staphylococcus","Streptococcus") 
  
  ps <-  ps %>% transform_sample_counts(function(x) x/sum(x) )  
  TaxTab <- tax_table(ps) %>% as.data.frame()
  taxa_names(ps) <- TaxTab$REC 
  allTaxa <- taxa_names(ps)
  ps.other <- prune_taxa(allTaxa[!(allTaxa %in% ExpTaxa)], ps)
  taxa.other <- ps.other@tax_table[,7] %>% as.character() # 7 for REC level 
  
  # change the taxa that are not the expected taxa to "Other" 
  TaxTab2 <- psmelt(ps)
  # merge/average per Sample and CheeseOutcome
  TaxTab2_agg <- aggregate(Abundance ~ TaxTab2[[var1]] + TaxTab2[[var2]] + REC,
                           data = TaxTab2,
                           mean)
  colnames(TaxTab2_agg)[1] <- var1
  colnames(TaxTab2_agg)[2] <- var2
  TaxTab2_agg$REC <- as.character(TaxTab2_agg$REC)
  TaxTab2_agg[TaxTab2_agg$REC %in% taxa.other,]$REC <- "Other"
  
  # Set colors for plotting
  mycol = c("#a6cee3","#1f78b4","#b2df8a","#33a02c","#fb9a99","#e31a1c",
            "#fdbf6f","#ff7f00","#cab2d6","#6a3d9a","#ffff99","#b15928")
  
  # Set orders for taxonomy and sampleID
  TaxTab2_agg$REC = factor(TaxTab2_agg$REC, levels = c(ExpTaxa, "Other"))
  if (!is.null(lvl)) TaxTab2_agg[[var1]] <- factor(TaxTab2_agg[[var1]], levels = lvl)
  if (!is.null(lvl2)) TaxTab2_agg[[var2]] <- factor(TaxTab2_agg[[var2]], levels = lvl2)
  
  pdf(path.out, width = w, height = h)
  p <- ggplot(TaxTab2_agg, aes(x = get(var1), y = Abundance, fill = REC)) +
    facet_grid(. ~ get(var2), scales = "free_x") + 
    geom_bar(stat = "identity") + 
    scale_fill_manual(values = mycol)+
    theme_bw(base_size = 15)+
    guides(fill = guide_legend(reverse = FALSE, keywidth = 1, keyheight = 1)) +
    ylab("Relative proportion")
  
  # convert ggplot object to grob object
  gp <- ggplotGrob(p)
  # optional: take a look at the grob object's layout 
  # gtable::gtable_show_layout(gp)
  # get gtable columns corresponding to the facets 
  facet.columns <- gp$layout$l[grepl("panel", gp$layout$name)]
  # get the number of unique x-axis values per facet (1 & 3, in this case)
  x.var <- sapply(ggplot_build(p)$layout$panel_scales_x, 
                  function(l) length(l$range$range))
  # change the relative widths of the facet columns based on how many unique 
  # x-axis values are in each facet
  gp$widths[facet.columns] <- gp$widths[facet.columns] * x.var
  # plot result
  grid::grid.draw(gp)
  dev.off()
}

# Read in sample ID order 
lvl.ID <- read.csv(file.path(path, "mapping/phase3_sample_orders.csv"), header = FALSE) 
lvl.ID$V1 <- as.character(lvl.ID$V1)
TaxBar(psList[[7]], var1 = "SampleID", var2 = "Kit", lvl = lvl.ID$V1,
       path.out = file.path(path,"feature_table/ps7_SampleID_Kit.pdf"), w = 9, h = 5)
TaxBar(psList[[7]], var1 = "SampleID", var2 = "Lysis", lvl = lvl.ID$V1, 
       lvl2 = c("Expected", "Bead beat: 2min x 6.5m/s", "Vortex: 15min", 
                "Chemical: 1hr", "Bead beat: 10s x 4m/s",
                "Chemical + Bead beat: 1hr + 10s x 4m/s",
                "Vortex: 30s", "Chemical + Vortex: 1hr + 30s "),
       path.out = file.path(path,"feature_table/ps7_SampleID_Lysis.pdf"), w = 9, h = 5)


# Plot for sample storage conditions (ps5)
TaxBar(subset_samples(psList[[5]], For_AVE %in% c("Glycerol","PBS2","Expected2")),  
       # subset to include only BCMC2 samples 
       var1 = "SampleID", var2 = "For_AVE",
       lvl = c("Theo2.1","Theo2.2","Theo2.3",
               "MC.PBS.1","MC.PBS.2","MC.PBS.3",
               "MC.25.glycerol.1","MC.25.glycerol.2","MC.25.glycerol.3"), 
       lvl2 = c("Expected2","PBS2", "Glycerol"),
       path.out = file.path(path, "feature_table/ps5_SampleID_For_AVE.pdf"), 5, 5)

# Plot for milk volumne collection (ps6)
TaxBar(subset_samples(psList[[6]], SampleID != "Theo2.2" & SampleID != "Theo2.3" &  
                        # subset to contain only one expected value
                        SampleID != "10TB.1" & SampleID != "10TB.2" & SampleID != "10TB.3"),
                        # subset to include only one set of 10ml samples
       var1 = "SampleID", var2 = "For_AVE",
       lvl = c("Theo2.1","MC.30ml.UHT.1","MC.30ml.UHT.2","MC.30ml.UHT.3",
               "MC.10ml.UHT.1","MC.10ml.UHT.2","MC.10ml.UHT.3",
               "MC.1ml.UHT.1","MC.1ml.UHT.2","MC.1ml.UHT.3","200TB.1","200TB.2","200TB.3"),
       lvl2 = c("Expected","30ml","10ml","1ml","200uL"),
       path.out = file.path(path, "feature_table/ps6_SampleID_For_AVE.pdf"),7.5,5)

# Plot for PMA (ps4)
TaxBar(subset_samples(psList[[4]], SampleID != "Theo2.2" & SampleID != "Theo2.3"), 
       var1 = "SampleID", var2 = "For_AVE",
       lvl = c("Theo2.1", "MC.50.control.1","MC.live.control.1","MC.dead.control.1",
               "MC.live.1","Mc.live.2","MC.live.3","MC.50.1","MC.50.2","MC.50.3",
               "MC.dead.1","MC.dead.2","MC.dead.3"),
       lvl2 = c("Expected","Untreated","Live","Half","Dead"),
       path.out = file.path(path, "feature_table/ps4_SampleID_For_AVE.pdf"),7,5)

```

#### Taxonomy plot for average values
```{r}

```


### For alpha and beta div based on ps.REC.glom after rarefaction (ps.REC.glom.rare)
I did not use ps.Phy05 for beta because the expected ASV is not the same as the actual sequenced ASV. If use ps.Phy05, the Bray distance of samples from expected would all be 1 (doesn't share any common species). The assumption is that the taxa assignment is accurate until Genus. Therefore, for alpha diversity, I would also use ps.REC.glom to keep until Genus level.
```{r include=FALSE}
ps.glom.rare <-  rarefy_even_depth(ps.REC.glom, sample.size = 3990, 
                                   replace = TRUE, rngseed = 123 , 
                                   trimOTUs = TRUE, verbose = TRUE)
# Divide the phyloseq objects up 
psList.rare <- list()
for (i in 1:8){
  psList.rare[[i]] <- phyloseq(sample_data(samdfList[[i]]), otu_table(ps.glom.rare),
                               tax_table(ps.glom.rare), phy_tree(ps.glom.rare))
  print(psList.rare[[i]] )
}

# Define function to get distance matrix (not include unifrac)
# I have to use distance() from vegan packages due to in compatibility 
# https://github.com/joey711/phyloseq/issues/918
DistTab <- function(ps, DistMethod){
  df <- psmelt(ps)
  df.cast <- dcast(df, For_AVE + SampleID ~ OTU, value.var = "Abundance")
  df.cast <- df.cast[,-1]
  row.names(df.cast) <- df.cast[,1]
  df.cast <- df.cast[,-1]
  dist <- vegdist(df.cast, method = DistMethod) %>% as.matrix()
}


# use the function to write bray distance list and write out as csv files
BrayList <- lapply(psList.rare, DistTab, DistMethod = "bray")
names(BrayList) <- c(1:8)
mapply(write.csv, BrayList, file = paste0(path, "distance/bray_", names(BrayList), ".csv"))

# write out weighted list as well
WeightList <- lapply(psList.rare, UniFrac, weighted = TRUE)
WeightList <- lapply(WeightList, as.matrix)
names(WeightList) <- c(1:8)
mapply(write.csv, WeightList, file = paste0(path, "distance/weighted_", names(WeightList), ".csv"))

# Define function to make box plot and add p-values to the plot 
## based on the package called "ggpubr"
DistBox <- function(df, DistMethod, path.out, w, h) {
  df$Description <- factor(df$Description, 
                         levels = c("10TB", "10TV", "10TC",
                                    "10CB", "10CV", "10CC",
                                    "10UB", "10UV", "10UC",
                                    "M4W","M4R","ML4W","ML4R","MVW","MVR","MLVW","MLVR",
                                    "P4W","P4R","PL4W","PL4R","PVW","PVR","PLVW","PLVR"))
  df$Kit <- factor(df$Kit, levels = c("Total","Core","Ultra2",
                                    "Total_phase3", "Total_ProteinaseK"))
  df$Lysis <- factor(df$Lysis, 
                   levels = c("Bead beat: 2min x 6.5m/s", "Vortex: 15min",
                              "Chemical: 1hr", "Bead beat: 10s x 4m/s",
                              "Chemical + Bead beat: 1hr + 10s x 4m/s",
                              "Vortex: 30s", "Chemical + Vortex: 1hr + 30s "))
  
  pdf(path.out, w, h )
  (ggboxplot(df, x = "Description", y = "ave", ylab = DistMethod,
             fill = "Lysis", palette = "Set3",
             short.panel.labs = FALSE, 
             font.label = list(size = 18, face = "plain"),
             ggtheme = theme_bw()) + 
     stat_compare_means(method = "t.test", ref.group = "10TB",
                        hide.ns = TRUE,  label = "p.signif")) %>% print
  dev.off()
  
  # ns: p > 0.05
  # *: p <= 0.05
  # **: p <= 0.01
  # ***: p <= 0.001
  # ****: p <= 0.0001
}

# Import organized and subsetted (only extraction) distance csv file for making bar plots
Bray.ext <- read.csv(file.path(path, "distance/organized_distance_extraction_bray.csv"))
DistBox(Bray.ext, DistMethod = "Bray-Curtis dissimilarity",
        path.out = file.path(path,"distance/Bray.ext.pdf"), w = 8, h = 4.5)

weighted.ext <- read.csv(file.path(path, "distance/organized_distance_extraction_weighted.csv"))
DistBox(weighted.ext, DistMethod = "Weighted UniFrac distance",
        path.out = file.path(path,"distance/Weigted.ext.pdf"), w = 8, h = 4.5)



# Define function to draw cluster dendrogram
DistDendro <- function(dist, ClusterMethod, path.out, w, h){
  pdf(path.out, w, h)
  hclust(as.dist(dist), method = ClusterMethod) %>% plot() %>% print()
  dev.off()
}


# dendrogram for ps5.rare
Bray5 <- DistTab(subset_samples(psList.rare[[5]], For_AVE %in% c("Glycerol","PBS2","Expected2")),
                 "bray")
DistDendro(dist = Bray5, ClusterMethod = "average",
           path.out = file.path(path, "distance/UPGMA_bray.pdf"), w = 7, h = 4.5)
Wuf5 <- UniFrac(subset_samples(psList.rare[[5]], For_AVE %in% c("Glycerol","PBS2","Expected2")),
                weighted = TRUE)
DistDendro(dist = Wuf5, ClusterMethod = "average",
           path.out = file.path(path, "distance/UPGMA_weighted.pdf"), w = 7, h = 4.5)



# Define function to plot 2D beta diversity dot plot
BetaPlot <- function(ps, ClusterMethod, DistMethod, var1, w, h, path.out){
  ps.ord <- ordinate(ps, method = ClusterMethod, distance = DistMethod)
  
  pdf(path.out, w, h)
  print(plot_ordination(ps, ps.ord, color = var1) + 
          geom_point(size=3)+ 
          scale_color_brewer(palette="Paired")+
          ggtitle("")+
          ylab("NMDS2")+ 
          xlab("NMDS1")+
          theme_bw(base_size = 15))
  dev.off()
}


# ps6 (sample volume)
BetaPlot(subset_samples(psList.rare[[6]], SampleID != "10TB.1" & SampleID != "10TB.2" & SampleID != "10TB.3"),
         ClusterMethod = "NMDS", DistMethod = "bray", var1 = "For_AVE",
         path.out = file.path(path, "beta/ps6_NMDS_bray.pdf"), 5, 3.6)

# ps 4 (PMA)
BetaPlot(psList.rare[[4]], ClusterMethod = "NMDS", DistMethod = "bray", var1 = "For_AVE",
         path.out = file.path(path, "beta/ps4_NMDS_bray.pdf"), 5, 3.6)

```


#### Alpha diversity
```{r}
# Define function that plots out alpha box plot as well as p values
AlphaBox <- function(ps, alpha_measures, var1, var, lvl, path.out, w, h){
  df <- estimate_richness(ps, split = TRUE, measures = alpha_measures) 
  row.names(df) <- gsub("X","",row.names(df) )
  # add sample metadata information
  df <- merge(df, data.frame(sample_data(ps)), by.x = 'row.names', by.y = 'row.names')
  df <- df[, -1]
  # Melt dataframe for plotting figures
  dfm <- melt(df, id.vars = c("SampleID", var),
              variable.name = "measure", value.name = "value")
  dfm[[var1]] <- factor(dfm[[var1]], levels = lvl)
  
  pdf(path.out, w, h)
  p<- ggboxplot(dfm, x = var1, y = "value", add = "jitter", palette = "Set3",
                font.label = list(size = 18, face = "plain"), ggtheme = theme_bw())+
    stat_compare_means(method = "t.test", ref.group = "Expected", 
                       hide.ns = TRUE,  label = "p.signif")

  facet(p, facet.by = "measure", scales = "free") %>% print()
  dev.off()
}

# Alpha box plot on ps6 (sample volume)
AlphaBox(subset_samples(psList.rare[[6]], SampleID != "10TB.1" & SampleID != "10TB.2" & SampleID != "10TB.3"),
         # subset to include only one set of 10ml samples 
         alpha_measures = c("Observed", "Shannon"),
         var1 = "For_AVE", var = c("KIT","For_AVE","STORAGE","MATRIX","PMA",
                                   "SampleOrCtrl","LYSING","Chemical_time",
                                   "Bead_beat_speed_time","vortex_time","Description"),
         lvl = c("Expected","30ml","10ml","1ml","200uL"),
         path.out = file.path(path, "alpha/ps6_ForAVE.pdf"), 4.5, 2.3)

# Alpha box plot on ps 4 (PMA)
AlphaBox(psList.rare[[4]], alpha_measures = c("Observed", "Shannon"),
         var1 = "For_AVE", var = c("KIT","For_AVE","VOL","STORAGE","MATRIX","PMA",
                                   "SampleOrCtrl","LYSING","Chemical_time",
                                   "Bead_beat_speed_time","vortex_time","Description"),
         lvl = c("Expected","Untreated","Live","Half","Dead"),
         path.out = file.path(path, "alpha/ps4_ForAVE.pdf"), 4.5, 2.3)

```


## qPCR results 
### PMA on single bacterial strain or gDNA 
```{r}
# PMA on E.coli gDNA 
PMA.conc <- read.csv(file.path(path, "qPCR/10min_conc.csv"))
gghistogram(PMA.conc, x = "Ct_diff",
            add = "mean", rug = TRUE, color = "Treatment", fill = "Treatment",
            palette = c("#00AFBB", "#E7B800"))
pdf(file.path(path, "qPCR/10min_conc.pdf"), 3.2, 3)
print(ggboxplot(PMA.conc, x = "Treatment", y = "Ct_diff",
                font.label = list(size = 18, face = "plain"), 
                ggtheme = theme_bw()) +
        stat_compare_means(method = "kruskal", hide.ns = TRUE, label = "p.signif"))
dev.off()

# PMA on 3 species strain 
PMA.T <- read.csv(file.path(path, "qPCR/50uM_time.csv"))
PMA.T$Cell_state <- factor(PMA.T$Cell_state, levels = c("Live", "Half", "Dead"))
## make a df to p value annotation
df.anno = compare_means(PerOf_untreated ~ Treatment, method = "kruskal.test",
                        group.by = "Species", data = PMA.T) %>% mutate(y_pos = 40)

pdf(file.path(path, "qPCR/50uM_time.pdf"), 6, 3)
print(ggboxplot(subset(PMA.T, PerOf_untreated != "NA"), 
                x = "Treatment", y = "PerOf_untreated", color = "Cell_state",
                font.label = list(size = 18, face = "plain"), 
                palette = "jco", ggtheme = theme_bw()) +
        facet_wrap(~Species, scales = "free_x"))
dev.off()

# PMA on MC 
PMC.mc <- read.csv(file.path(path,"qPCR/MC_total.csv"))
PMC.mc$Cell_state <- factor(PMC.mc$Cell_state, levels = c("Live", "Half", "Dead"))

pdf(file.path(path, "qPCR/PMC.mc.pdf"), 3.2, 3)
print(ggboxplot(subset(PMC.mc, PerOf_untreated != "NA"), 
                x = "Cell_state", y = "PerOf_untreated", color = "Cell_state",
                font.label = list(size = 18, face = "plain"), 
                palette = "jco", ggtheme = theme_bw()) +
        stat_compare_means(method = "kruskal.test", hide.ns = TRUE,  label = "p.signif"))
dev.off()
```


## Use decontam package to see if by removing the UHT taxa, the vol (ps6) will be better
```{r eval=FALSE, include=FALSE}
# Read in ps.Phy05 (not glom at any taxonomy level) to subset vol samples 
samdf6d <- read.csv(file.path(path, "mapping/MC_paper2_samdf_total_vol_decontam.csv"))
rownames(samdf6d) <- samdf6d$SampleID
ps6d <- phyloseq(sample_data(samdf6d), otu_table(ps.Phy05),
                 tax_table(ps.Phy05), phy_tree(ps.Phy05))
ps6d # 197 taxa and 22 samples 

# Inspect library sizes
## add a colum for read counts/library size
samdf6d$LibrarySize <- sample_sums(ps6d)
## sort by the library size in increasing order
samdf6d <- samdf6d[order(samdf6d$LibrarySize),]
samdf6d$Index <- seq(nrow(samdf6d))
ggplot(samdf6d, aes(x=Index, y=LibrarySize, color=SampleOrCtrl))+geom_point()

# Identify contaminants using the prevalance pooled method
## sort the rownames of seq feature table
SeqTab6d <- otu_table(ps6d) %>% data.frame() %>% t()
rownames(SeqTab6d) <- gsub("X","", row.names(SeqTab6d))
SeqTab6d <- SeqTab6d[order(row.names(SeqTab6d)),]
## sort the sample metadata file 
samdf6d <- samdf6d[order(row.names(samdf6d)),]
## check to see if the row names of these two matrices match 
identical(row.names(SeqTab6d), row.names(samdf6d)) 
## define negative control samples
is.neg <- samdf6d$SampleOrCtrl %in% "Ctrl"
samdf6d$is.neg <- is.neg


# Find a suitable p value based on ASV number
library(decontam);packageVersion("decontam")
decontam.pool <- isContaminant(seqtab = SeqTab6d, neg = is.neg, 
                               method = "prevalence", threshold = 0.1,
                               normalize = TRUE)
table(decontam.pool$contaminant)
threshs <- seq(0, 1, length.out = 101)
## merge p values as dataframe with taxTab output
pval <- data.frame(id=row.names(decontam.pool), pval.po=decontam.pool$p)
row.names(pval) <- pval$id
pval <- pval[order(pval$id),]
TaxTab6d <- tax_table(ps6d) %>% data.frame()
TaxTab6d$Id <- row.names(TaxTab6d)
TaxTab6d <- TaxTab6d[order(row.names(TaxTab6d)),]
identical(row.names(pval),row.names(TaxTab6d))
TaxTab6d <- merge(TaxTab6d, pval, by.x = 'Id', by.y = 'id', all.x = TRUE, sort=FALSE)
## get p-values and define group
p.pool <- data.frame(x= 1:dim(TaxTab6d)[1])
p.pool$pval <- TaxTab6d$pval.po
p.pool$Method <- "pool"
p.pool <- p.pool[,-1]
## visualize the threshold results
ggplot(p.pool, aes(pval, fill=Method))+ geom_histogram()

# Find a suitable p value based on reads number
## get total read number 
totSeqTab <- sum(SeqTab6d)
p.reads <- data.frame(pool=sapply(threshs, function(t) sum(SeqTab6d[,decontam.pool$p<t],
                                                           na.rm=TRUE)/totSeqTab),
                      threshold=threshs)
mp.reads <- melt(p.reads, id.vars="threshold", value.name="Fraction.reads", 
                 variable.name="Method") #m prefix for melt
ggplot(data=mp.reads, aes(x=threshold, y=Fraction.reads, color=Method)) + 
  geom_line() + geom_point() + xlim(0,1) + ylim(0,1) +
  scale_color_manual(values=c("pool"="black")) +
  theme_bw() + 
  xlab("P-value Threshold") + 
  ylab("Reads IDed as Contaminants\n(Proportion)") #f prefix for figure

# Identify contaminants using the prevalance pooled method with p=0.25
decontam.p.25 <- isContaminant(seqtab = SeqTab6d, neg = is.neg, 
                               method = "prevalence",threshold = 0.25, normalize = TRUE)
table(decontam.p.25$contaminant)

# Make phyloseq object of presence-absence in negative controls
ps.neg <- prune_samples(sample_data(ps6d)$SampleOrCtrl %in% c("Ctrl"), ps6d)
ps.neg.presence <- transform_sample_counts(ps.neg, function(abund) 1*(abund>0))
# Make phyloseq object of presence-absence in true positive samples
ps.pos <- prune_samples(sample_data(ps6d)$SampleOrCtrl %in% c("Sample"), ps6d)
ps.pos.presence <- transform_sample_counts(ps.pos, function(abund) 1*(abund>0))
# Make data.frame of prevalence in positive and negative samples
df.pres <- data.frame(prevalence.pos=taxa_sums(ps.pos.presence),
                      prevalence.neg=taxa_sums(ps.neg.presence),
                      contam.prev=decontam.p.25$contaminant)
ggplot(data=df.pres, aes(x=prevalence.neg, y=prevalence.pos, color=contam.prev))+
  geom_point()

# Remove identified contaminants
rm <- subset(decontam.p.25, p < 0.25) %>% row.names()
SeqTab6d.25 <- select(as.data.frame(SeqTab6d),-one_of(rm))

# Merge as a phyloseq object after decontam 
ps6d.25 <- phyloseq(sample_data(samdf_total_vol), 
                    otu_table(SeqTab6d.25, taxa_are_rows = FALSE),
                    tax_table(ps6d), phy_tree(ps6d))
ps6d.25 # 150 taxa and 22 samples 
ps6d.25 <- tax_glom(ps6d.25, taxrank = "Genus", NArm = FALSE)
ps6d.25 <- RECps(TaxTab, ps6d.25)
ps6d.25 # 80 taxa and 18 samples

# individual sample taxa plot
TaxBar(subset_samples(ps6d.25, SampleID != "Theo2.2" & SampleID != "Theo2.3" &  
                        # subset to contain only one expected value
                        SampleID != "10TB.1" & SampleID != "10TB.2" & SampleID != "10TB.3"),
                        # subset to include only one set of 10ml samples
       var1 = "SampleID", var2 = "For_AVE",
       lvl = c("Theo2.1","MC.30ml.UHT.1","MC.30ml.UHT.2","MC.30ml.UHT.3",
               "MC.10ml.UHT.1","MC.10ml.UHT.2","MC.10ml.UHT.3",
               "MC.1ml.UHT.1","MC.1ml.UHT.2","MC.1ml.UHT.3","200TB.1","200TB.2","200TB.3"),
       lvl2 = c("Expected","30ml","10ml","1ml","200uL"),
       path.out = file.path(path, "feature_table/ps6d.25_SampleID_For_AVE.pdf"),7.5,5)
```
At the end, the decontam package did not remove much of the contaminant, unexpected
taxa. Therefore, I decided to take a closer look by manually examine the taxtab.
Also, I want to find out if, for example, the Bacillus in MC is the same ASV as 
in UHT. If not, I may be able to perform manual filtering.

## Manual filtering to see if by removing the UHT taxa, the vol (ps6) will be better
```{r eval=FALSE, include=FALSE}
# write out featuretab
transform_sample_counts(ps6d, function(x) x/sum(x)) %>% psmelt() %>% 
  dcast(For_AVE + SampleID ~ OTU, value.var = "Abundance") %>% 
  write.csv(file.path(path, "feature_table/FeatTab_6d_ASV.csv"))
# write out taxtab
(ps6d@tax_table) %>% 
  write.csv(file.path(path, "tax_table/TaxTab_6d_ASV.csv"))

# Yes there are some OTU overlap. Can not remove
```



Percent recovery of GBS DNA with meconium extractions
generated from various extraction kits. Data are mean Â± S


